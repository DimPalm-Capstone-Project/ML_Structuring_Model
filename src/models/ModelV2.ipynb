{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XqxQ_8qfcceO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Lambda, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVJmf4-cdydZ"
   },
   "outputs": [],
   "source": [
    "data_dir = '/CAPSTONE-PROJECT/data/aug/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PpxIw9l7d4JC"
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Baca data dari direktori aug\n",
    "    for person_dir in os.listdir(data_dir):\n",
    "        person_path = os.path.join(data_dir, person_dir)\n",
    "        if os.path.isdir(person_path):\n",
    "            person_id = int(person_dir.split('_')[-1])\n",
    "            image_paths = glob(os.path.join(person_path, '*.jpg'))\n",
    "\n",
    "            for image_path in image_paths:\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                image = cv2.resize(image, (128, 128))\n",
    "                image = image / 255.0  # Normalisasi ke rentang 0-1\n",
    "                X.append(image)\n",
    "                y.append(person_id)\n",
    "\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EArBTp6xeBeW",
    "outputId": "c75ffa2a-2563-4ca6-ceb6-de0255ee27c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data: 200\n",
      "Ukuran input: (128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Baca dan preprocess data\n",
    "X, y = load_and_preprocess_data(data_dir)\n",
    "print(f\"Jumlah data: {len(X)}\")\n",
    "print(f\"Ukuran input: {X.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8UmNNOSnunCS"
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 128, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "oFo4I_LgufYa",
    "outputId": "53d391df-d1bb-40d2-9c1e-fa06a5574743"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'def load_image(file_path, target_size=(128, 128)):\\n    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\\n    image = cv2.resize(image, target_size)\\n    image = image.astype(\"float32\") / 255.0  # Normalisasi\\n    return np.expand_dims(image, axis=-1)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fungsi untuk memuat gambar dan resize\n",
    "def load_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Membaca gambar grayscale\n",
    "    img = cv2.resize(img, (img_width, img_height))  # Resize gambar\n",
    "    img = img.astype('float32') / 255.0  # Normalisasi\n",
    "    img = np.expand_dims(img, axis=-1)  # Menambahkan dimensi channel\n",
    "    return img\n",
    "\n",
    "'''def load_image(file_path, target_size=(128, 128)):\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image.astype(\"float32\") / 255.0  # Normalisasi\n",
    "    return np.expand_dims(image, axis=-1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "v7mXbGA3fBrQ"
   },
   "outputs": [],
   "source": [
    "def create_pairs(directory):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    people = os.listdir(directory)\n",
    "\n",
    "    for person in people:\n",
    "        person_path = os.path.join(directory, person)\n",
    "        images = os.listdir(person_path)\n",
    "        for i in range(len(images)):\n",
    "            for j in range(i + 1, len(images)):\n",
    "                img1 = load_image(os.path.join(person_path, images[i]))\n",
    "                img2 = load_image(os.path.join(person_path, images[j]))\n",
    "                pairs.append([img1, img2])\n",
    "                labels.append(1)  # Pair positif (gambar dari orang yang sama)\n",
    "\n",
    "        for other_person in [p for p in people if p != person]:\n",
    "            other_path = os.path.join(directory, other_person)\n",
    "            other_image = load_image(os.path.join(other_path, os.listdir(other_path)[0]))\n",
    "            pairs.append([img1, other_image])\n",
    "            labels.append(0)  # Pair negatif (gambar dari orang berbeda)\n",
    "\n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "75Yp1iLJpoH_"
   },
   "outputs": [],
   "source": [
    "def build_siamese_model(input_shape=(128, 128, 1)):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (10, 10), activation='relu')(input)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(128, (7, 7), activation='relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(128, (4, 4), activation='relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(256, (4, 4), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation='sigmoid')(x)\n",
    "    model = Model(input, x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bLb6uu5zprNF"
   },
   "outputs": [],
   "source": [
    "def build_full_model(input_shape=(128, 128, 1)):\n",
    "    base_model = build_siamese_model(input_shape)\n",
    "\n",
    "    input_a = Input(shape=input_shape)\n",
    "    input_b = Input(shape=input_shape)\n",
    "\n",
    "    processed_a = base_model(input_a)\n",
    "    processed_b = base_model(input_b)\n",
    "\n",
    "    # Lambda layer untuk menghitung jarak L1\n",
    "    distance = Lambda(lambda embeddings: tf.abs(embeddings[0] - embeddings[1]))([processed_a, processed_b])\n",
    "    output = Dense(1, activation=\"sigmoid\")(distance)\n",
    "    model = Model([input_a, input_b], output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "0h1gBv1Ypt4H",
    "outputId": "eb431923-3173-4bc0-d746-f6f95a5faef9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ functional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">68,307,776</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                           │                        │                │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ functional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                           │                        │                │ functional[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,097</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ functional (\u001b[38;5;33mFunctional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │     \u001b[38;5;34m68,307,776\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                           │                        │                │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ functional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                           │                        │                │ functional[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │          \u001b[38;5;34m4,097\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,311,873</span> (260.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m68,311,873\u001b[0m (260.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,311,873</span> (260.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,311,873\u001b[0m (260.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_full_model()\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.0001), metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qs2GTu4RpwbN"
   },
   "outputs": [],
   "source": [
    "# Load pasangan data\n",
    "pairs, labels = create_pairs(data_dir)\n",
    "\n",
    "# Split data menjadi training dan validation (contoh 80-20 split)\n",
    "from sklearn.model_selection import train_test_split\n",
    "(pairs_train, pairs_val, labels_train, labels_val) = train_test_split(pairs, labels, test_size=0.2, random_state=42\n",
    "                                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "s5Z9TARpFjSC"
   },
   "outputs": [],
   "source": [
    "# Callback untuk early stopping jika val_accuracy tidak meningkat\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Callback untuk mengurangi learning rate jika val_loss stagnan\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T2Z2PyTZqQdJ",
    "outputId": "b1950890-8d3f-4a34-bcb5-98ab6568ac9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m857s\u001b[0m 17s/step - accuracy: 0.9310 - loss: 0.5560 - val_accuracy: 0.9447 - val_loss: 0.4252 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m892s\u001b[0m 18s/step - accuracy: 0.9550 - loss: 0.3948 - val_accuracy: 0.9447 - val_loss: 0.2964 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m906s\u001b[0m 18s/step - accuracy: 0.9511 - loss: 0.3260 - val_accuracy: 0.9447 - val_loss: 0.3100 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m46/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:04\u001b[0m 16s/step - accuracy: 0.9514 - loss: 0.3111"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "history = model.fit(\n",
    "    [pairs_train[:, 0], pairs_train[:, 1]], labels_train[:],\n",
    "    validation_data=([pairs_val[:, 0], pairs_val[:, 1]], labels_val[:]),\n",
    "    batch_size=16,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZUdNrPP9rvI"
   },
   "outputs": [],
   "source": [
    "def plot_scores(train):\n",
    "    accuracy = train.history['accuracy']\n",
    "    val_accuracy = train.history['val_accuracy']\n",
    "    epochs = range(len(accuracy))\n",
    "    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n",
    "    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n",
    "    plt.title('Scores')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def plot_loss(train):\n",
    "    loss = train.history['loss']\n",
    "    val_loss = train.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'b', label='Loss apprentissage')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Loss validation')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_scores(history)\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0dF549hfwWc"
   },
   "outputs": [],
   "source": [
    "'''# Contrastive loss\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvWR1_awnsrB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
